#!/usr/bin/env python3
"""
FRIDAY Self-Tuning Script â€” Live LoRA Adapter Generator
- Scans finalized memory threads
- Builds fine-tune-ready dataset
- Runs LoRA-based continual tuning
- Outputs to `loftq_live/` and logs results
"""
import os
import time
import json
from datetime import datetime
from pathlib import Path
from peft import LoraConfig, get_peft_model
from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling
from datasets import load_dataset, Dataset
import torch

# â”€â”€â”€ Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_MODEL = "mistralai/Mistral-7B-Instruct-v0.3"
DATA_PATH = "friday/memory/default.jsonl"
OUTPUT_DIR = "models/friday_0.2.2/loftq_live"
MAX_TRAINING_SHARDS = 200  # cap to avoid drift

# â”€â”€â”€ Build Fine-tune Dataset from Memory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_memory(file_path):
    samples = []
    seen_threads = set()
    with open(file_path, 'r') as f:
        for line in f:
            shard = json.loads(line)
            if "tags" in shard and any(tag in shard["tags"] for tag in ["persona_shift", "symbolic", "novelty"]):
                samples.append({
                    "messages": [
                        {"role": "user", "content": "What were we talking about?"},
                        {"role": "assistant", "content": shard['text']}
                    ]
                })


            seen_threads.add(shard['thread_id'])
            samples.append({
                "messages": [
                    {"role": "user", "content": "What were we talking about?"},
                    {"role": "assistant", "content": shard['text']}
                ]
            })
            if len(samples) >= MAX_TRAINING_SHARDS:
                break
    return samples

# â”€â”€â”€ Save as JSONL Dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def write_jsonl(data, out_path):
    with open(out_path, "w") as f:
        for entry in data:
            f.write(json.dumps(entry) + "\n")

# â”€â”€â”€ Main Tuning Routine â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_self_tune():
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    run_dir = Path(OUTPUT_DIR) / f"run_{timestamp}"
    run_dir.mkdir(parents=True, exist_ok=True)

    print("ðŸ§  Extracting memory threads...")
    samples = load_memory(DATA_PATH)
    dataset_path = run_dir / "memory_batch.jsonl"
    write_jsonl(samples, dataset_path)

    print("ðŸ“¦ Loading dataset...")
    raw_ds = load_dataset("json", data_files=str(dataset_path))['train']

    print("ðŸ”§ Preparing model + LoRA config...")
    model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, torch_dtype=torch.float16)
    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)
    tokenizer.pad_token = tokenizer.eos_token

    lora_config = LoraConfig(
        r=16,
        lora_alpha=32,
        target_modules=["q_proj", "v_proj"],
        lora_dropout=0.05,
        bias="none",
        task_type="CAUSAL_LM"
    )
    model = get_peft_model(model, lora_config)

    def tokenize(example):
        return tokenizer.apply_chat_template(example['messages'], return_tensors="pt", truncation=True, max_length=2048)

    tokenized_ds = raw_ds.map(tokenize)

    print("ðŸš€ Starting training...")
    trainer = Trainer(
        model=model,
        train_dataset=tokenized_ds,
        args=TrainingArguments(
            output_dir=str(run_dir),
            per_device_train_batch_size=1,
            gradient_accumulation_steps=4,
            num_train_epochs=1,
            fp16=True,
            save_strategy="no",
            logging_steps=10,
        ),
        data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)
    )

    trainer.train()

    print("ðŸ’¾ Saving adapter weights...")
    model.save_pretrained(run_dir / "adapter")
    print(f"âœ… Self-tuning complete: {run_dir}")

if __name__ == "__main__":
    run_self_tune()

